{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeczzVxOe1NjYpcRt1JuT1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmilks/cap-comp215/blob/main/STAT305_Step_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyy4E24Op3yp"
      },
      "outputs": [],
      "source": [
        "#HURDAT Parsing -> Hurricane Objects w/ list of Entry objects\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from scipy.stats import ttest_ind\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Hurricane():\n",
        "    name: str\n",
        "    entries: list\n",
        "    year: str\n",
        "    basin: str\n",
        "    atfc: int\n",
        "\n",
        "    def __str__(self):\n",
        "        return f'Storm {self.name} in {self.year} with {len(self.entries)} entries.'\n",
        "\n",
        "    @classmethod\n",
        "    def from_splt_hur(cls,splt_hur):\n",
        "        splt_hur_head=[i.strip(' ') for i in splt_hur[0].split(',')]\n",
        "        new = Hurricane(name=splt_hur_head[1],\n",
        "                        year=int(splt_hur_head[0][-4:]),\n",
        "                        basin=splt_hur_head[0][:2],\n",
        "                        atfc=splt_hur_head[0][-6:-4],\n",
        "                        entries=[])\n",
        "        new.entries=Entry.entries_factory(splt_hur[1:])\n",
        "        return new\n",
        "\n",
        "    def total_max_wind(self):\n",
        "        max=0\n",
        "        for entry in self.entries:\n",
        "            if entry.max_wind > max:\n",
        "                max = entry.max_wind\n",
        "        return max\n",
        "\n",
        "    def max_min_pressure(self):\n",
        "        max=0\n",
        "        for entry in self.entries:\n",
        "            if entry.min_pressure > max:\n",
        "                max = entry.min_pressure\n",
        "        return max\n",
        "\n",
        "    def max_radius(self):\n",
        "        max=0\n",
        "        for entry in self.entries:\n",
        "            if entry.radius > max:\n",
        "                max = entry.radius\n",
        "        return max\n",
        "\n",
        "    def make_lf(self):\n",
        "        lfs = []\n",
        "        for entry in self.entries:\n",
        "            if entry.identifier == 'L':\n",
        "                lfs.append(entry)\n",
        "        if lfs:\n",
        "            return lfs\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "@dataclass\n",
        "class Entry():\n",
        "    date: datetime\n",
        "    identifier: str\n",
        "    status: str\n",
        "    coordinates: tuple\n",
        "    max_wind: int\n",
        "    min_pressure: int\n",
        "    radius: int\n",
        "\n",
        "    def __str__(self):\n",
        "        return f'{self.date} at {self.coordinates}\\nID: {self.identifier}, Status: {self.status}\\nMax Wind: {self.max_wind}, Min Pressure: {self.min_pressure}, Radius: {self.radius}'\n",
        "\n",
        "    @classmethod\n",
        "    def Factory(cls, entry):\n",
        "        return Entry(date=datetime.strptime(f\"{entry[0]}{entry[1]}\",'%Y%m%d%H%M'),\n",
        "                    identifier=entry[2],\n",
        "                    status=entry[3],\n",
        "                    coordinates=(entry[4], entry[5]),\n",
        "                    max_wind=int(entry[6]),\n",
        "                    min_pressure=int(entry[7]),\n",
        "                    radius=int(entry[20]))\n",
        "\n",
        "    @classmethod\n",
        "    def entries_factory(cls,raw_entries):\n",
        "        entries=[]\n",
        "        for entry in raw_entries:\n",
        "            entry_splt=[i.strip(' ') for i in entry.split(',')]\n",
        "            entries.append(Entry.Factory(entry_splt))\n",
        "        return entries\n",
        "\n",
        "splt_hurricanes_raw=[]\n",
        "with open(\"hurdat1923_2023.txt\",\"r\") as f:\n",
        "    hur=[]\n",
        "    for line in f:\n",
        "        if line[0].isalpha():\n",
        "            if hur != []:\n",
        "                splt_hurricanes_raw.append(hur)\n",
        "                hur=[]\n",
        "        hur.append(line.strip())\n",
        "\n",
        "hurricanes_classed=[]\n",
        "for i in splt_hurricanes_raw:\n",
        "    hurricanes_classed.append(Hurricane.from_splt_hur(i))\n",
        "\n",
        "hur_cat = []\n",
        "for i in hurricanes_classed:\n",
        "    hur_cat_ind = [f\"{i.name}{i.year}\"]\n",
        "    hur_cat_ind.append(i.entries[0].coordinates[0])\n",
        "    hur_cat_ind.append(i.entries[0].coordinates[1])\n",
        "    if i.make_lf():\n",
        "        hur_cat_ind.append(1)\n",
        "    else:\n",
        "        hur_cat_ind.append(0)\n",
        "    if i.total_max_wind() >= 96 and i.total_max_wind() <= 112:\n",
        "        hur_cat_ind.append(1)\n",
        "    else:\n",
        "        hur_cat_ind.append(0)\n",
        "    if i.total_max_wind() >= 113 and i.total_max_wind() <= 136:\n",
        "        hur_cat_ind.append(1)\n",
        "    else:\n",
        "        hur_cat_ind.append(0)\n",
        "    if i.total_max_wind() >= 137:\n",
        "        hur_cat_ind.append(1)\n",
        "    else:\n",
        "        hur_cat_ind.append(0)\n",
        "    hur_cat.append(hur_cat_ind)\n",
        "\n",
        "df_hur_cat = pd.DataFrame(hur_cat,columns=['ID','Lat','Long','Landfall','Cat. 3','Cat. 4','Cat. 5'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#True Lat/Long\n",
        "df_hur_cat['Lat'] = df_hur_cat['Lat'].apply(lambda x:float(x[:-1]))\n",
        "df_hur_cat['Long'] = df_hur_cat['Long'].apply(lambda x:float(x[:-1]))\n",
        "x=np.asarray(df_hur_cat[['Lat','Long']])\n",
        "x=preprocessing.StandardScaler().fit(x).transform(x)\n",
        "y=np.asarray(df_hur_cat['Landfall'])\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "print ('Train set:', x_train.shape,  y_train.shape)\n",
        "print ('Test set:', x_test.shape,  y_test.shape)\n",
        "\n",
        "LR = LogisticRegression(C=0.01,solver='liblinear').fit(x_train,y_train)\n",
        "yhat = LR.predict(x_test)\n",
        "yhat_prob = LR.predict_proba(x_test)\n",
        "print(metrics.accuracy_score(y_test,yhat))\n",
        "cm=confusion_matrix(y_test,yhat)\n",
        "print(cm)\n",
        "\n",
        "class_label = [\"Positive\", \"Negative\"]\n",
        "df_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\n",
        "sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
        "plt.title(\"True Lat/Long Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KiV63wrkp9t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 & 20 Lat\n",
        "df_hur_cat['Lat'] = df_hur_cat['Lat'].apply(lambda x:abs(float(x[:-1])-14))\n",
        "df_hur_cat['Long'] = df_hur_cat['Long'].apply(lambda x:abs(float(x[:-1])-55.7))\n",
        "x=np.asarray(df_hur_cat[['Lat','Long']])\n",
        "x=preprocessing.StandardScaler().fit(x).transform(x)\n",
        "y=np.asarray(df_hur_cat['Landfall'])\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "print ('Train set:', x_train.shape,  y_train.shape)\n",
        "print ('Test set:', x_test.shape,  y_test.shape)\n",
        "\n",
        "LR = LogisticRegression(C=0.01,solver='liblinear').fit(x_train,y_train)\n",
        "yhat = LR.predict(x_test)\n",
        "yhat_prob = LR.predict_proba(x_test)\n",
        "print(metrics.accuracy_score(y_test,yhat))\n",
        "cm=confusion_matrix(y_test,yhat)\n",
        "print(cm)\n",
        "\n",
        "class_label = [\"Positive\", \"Negative\"]\n",
        "df_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\n",
        "sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
        "plt.title(\"Absolute Lat/Long Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "stvw7YLgqWnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Category & Lat/Long\n",
        "df_hur_cat['Lat'] = df_hur_cat['Lat'].apply(lambda x:float(x[:-1]))\n",
        "df_hur_cat['Long'] = df_hur_cat['Long'].apply(lambda x:float(x[:-1]))\n",
        "for i in ['Cat. 3','Cat. 4','Cat. 5']:\n",
        "    x=np.asarray(df_hur_cat[['Lat','Long']])\n",
        "    x=preprocessing.StandardScaler().fit(x).transform(x)\n",
        "    y=np.asarray(df_hur_cat[i])\n",
        "\n",
        "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "    print ('Train set:', x_train.shape,  y_train.shape)\n",
        "    print ('Test set:', x_test.shape,  y_test.shape)\n",
        "\n",
        "    LR = LogisticRegression(C=0.01,solver='liblinear').fit(x_train,y_train)\n",
        "    yhat = LR.predict(x_test)\n",
        "    yhat_prob = LR.predict_proba(x_test)\n",
        "    print(i)\n",
        "    print(metrics.accuracy_score(y_test,yhat))\n",
        "    cm=confusion_matrix(y_test,yhat)\n",
        "    print(cm)\n",
        "    class_label = [\"Positive\", \"Negative\"]\n",
        "    df_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\n",
        "    sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
        "    plt.title(f\"{i} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"Actual Label\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "42thiiOvqYrE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}